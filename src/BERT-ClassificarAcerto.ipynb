{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\r\n",
    "from collections import defaultdict\r\n",
    "from datetime import datetime\r\n",
    "import time\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "import torch\r\n",
    "import torch.nn.functional as F\r\n",
    "from sklearn.metrics import classification_report, f1_score\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from torch import nn, optim\r\n",
    "from torch.utils.data import DataLoader, Dataset\r\n",
    "from transformers import (AdamW, BertModel, BertTokenizer,\r\n",
    "                          get_linear_schedule_with_warmup)\r\n",
    "\r\n",
    "from preprocessing.dataprep import filter_tce_data, text_preprocessing\r\n",
    "from preprocessing.text import fixColumnName\r\n",
    "\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "sns.set()\r\n",
    "\r\n",
    "RANDOM_SEED = 15\r\n",
    "PRE_TRAINED_MODEL_NAME = 'neuralmind/bert-base-portuguese-cased'\r\n",
    "MAX_LEN = 156\r\n",
    "BATCH_SIZE = 16\r\n",
    "EPOCHS = 10\r\n",
    "\r\n",
    "np.random.seed(RANDOM_SEED)\r\n",
    "torch.manual_seed(RANDOM_SEED)\r\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "class TCEDataset(Dataset):\r\n",
    "    def __init__(self, empenho_historico, targets, tokenizer, max_len):\r\n",
    "        self.empenho_historico = empenho_historico\r\n",
    "        self.targets = targets\r\n",
    "        self.tokenizer = tokenizer\r\n",
    "        self.max_len = max_len\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.empenho_historico)\r\n",
    "\r\n",
    "    def __getitem__(self, item):\r\n",
    "        text = str(self.empenho_historico[item])\r\n",
    "        target = self.targets[item]\r\n",
    "        encoding = self.tokenizer.encode_plus(\r\n",
    "            text,\r\n",
    "            add_special_tokens=True,\r\n",
    "            max_length=self.max_len,\r\n",
    "            return_token_type_ids=False,\r\n",
    "            padding='max_length',\r\n",
    "            return_attention_mask=True,\r\n",
    "            return_tensors='pt',\r\n",
    "            truncation=True\r\n",
    "        )\r\n",
    "        return {\r\n",
    "            'empenho_historico': text,\r\n",
    "            'input_ids': encoding['input_ids'].flatten(),\r\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\r\n",
    "            'targets': torch.tensor(target, dtype=torch.long)\r\n",
    "        }\r\n",
    "\r\n",
    "\r\n",
    "def create_data_loader(df, tokenizer, max_len, batch_size):\r\n",
    "    ds = TCEDataset(\r\n",
    "        empenho_historico=df.empenho_historico.to_numpy(),\r\n",
    "        targets=df.target.to_numpy(),\r\n",
    "        tokenizer=tokenizer,\r\n",
    "        max_len=max_len\r\n",
    "    )\r\n",
    "    return DataLoader(\r\n",
    "        ds,\r\n",
    "        batch_size=batch_size,\r\n",
    "    )\r\n",
    "\r\n",
    "\r\n",
    "class CorretudeClassifier(nn.Module):\r\n",
    "    def __init__(self, n_classes):\r\n",
    "        super(CorretudeClassifier, self).__init__()\r\n",
    "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\r\n",
    "        self.drop = nn.Dropout(p=0.3)\r\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\r\n",
    "\r\n",
    "    def forward(self, input_ids, attention_mask):\r\n",
    "        bert_output = self.bert(\r\n",
    "            input_ids=input_ids,\r\n",
    "            attention_mask=attention_mask\r\n",
    "        )\r\n",
    "\r\n",
    "        output = self.drop(bert_output['pooler_output'])\r\n",
    "        return self.out(output)\r\n",
    "\r\n",
    "\r\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\r\n",
    "    model = model.train()\r\n",
    "    losses = []\r\n",
    "    correct_predictions = 0\r\n",
    "    predictions = []\r\n",
    "    real_values = []\r\n",
    "    for d in data_loader:\r\n",
    "        input_ids = d[\"input_ids\"].to(device)\r\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\r\n",
    "        targets = d[\"targets\"].to(device)\r\n",
    "        outputs = model(\r\n",
    "            input_ids=input_ids,\r\n",
    "            attention_mask=attention_mask\r\n",
    "        )\r\n",
    "        _, preds = torch.max(outputs, dim=1)\r\n",
    "        loss = loss_fn(outputs, targets)\r\n",
    "        correct_predictions += torch.sum(preds == targets)\r\n",
    "        losses.append(loss.item())\r\n",
    "        loss.backward()\r\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\r\n",
    "        optimizer.step()\r\n",
    "        scheduler.step()\r\n",
    "        optimizer.zero_grad()\r\n",
    "        predictions.extend(preds)\r\n",
    "        real_values.extend(targets)\r\n",
    "    predictions = torch.stack(predictions).cpu()\r\n",
    "    real_values = torch.stack(real_values).cpu()\r\n",
    "    macro = f1_score(real_values, predictions, average='macro')\r\n",
    "    micro = f1_score(real_values, predictions, average='micro')\r\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses), macro, micro\r\n",
    "\r\n",
    "\r\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\r\n",
    "    model = model.eval()\r\n",
    "    losses = []\r\n",
    "    correct_predictions = 0\r\n",
    "    predictions = []\r\n",
    "    real_values = []\r\n",
    "    with torch.no_grad():\r\n",
    "        for d in data_loader:\r\n",
    "            input_ids = d[\"input_ids\"].to(device)\r\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\r\n",
    "            targets = d[\"targets\"].to(device)\r\n",
    "            outputs = model(\r\n",
    "                input_ids=input_ids,\r\n",
    "                attention_mask=attention_mask\r\n",
    "            )\r\n",
    "            _, preds = torch.max(outputs, dim=1)\r\n",
    "            loss = loss_fn(outputs, targets)\r\n",
    "            correct_predictions += torch.sum(preds == targets)\r\n",
    "            losses.append(loss.item())\r\n",
    "            predictions.extend(preds)\r\n",
    "            real_values.extend(targets)\r\n",
    "    predictions = torch.stack(predictions).cpu()\r\n",
    "    real_values = torch.stack(real_values).cpu()\r\n",
    "    macro = f1_score(real_values, predictions, average='macro')\r\n",
    "    micro = f1_score(real_values, predictions, average='micro')\r\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses), macro, micro\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation at 25/06/2021 14:44:53\n",
      "\n",
      "Loading data...\n",
      "Data loading time: 4.20s\n",
      "\n",
      "Preprocessing data...\n",
      "Data preparation time: 5.04s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\r\n",
    "start_date = datetime.now()\r\n",
    "print(f'Starting evaluation at {start_date.strftime(\"%d/%m/%Y %H:%M:%S\")}')\r\n",
    "print()\r\n",
    "print('Loading data...')\r\n",
    "\r\n",
    "data_loading_time = time.time()\r\n",
    "data = pd.read_excel('../database/dados_analisados.xlsx')\r\n",
    "print(f'Data loading time: {(time.time() - data_loading_time):.2f}s')\r\n",
    "print()\r\n",
    "\r\n",
    "data_prep_time = time.time()\r\n",
    "print('Preprocessing data...')\r\n",
    "\r\n",
    "# data = data.sample(1000,).reset_index(drop=True)\r\n",
    "data.columns = list(map(fixColumnName, data.columns))\r\n",
    "data, _ = filter_tce_data(data, '../database/norel.xlsx')\r\n",
    "\r\n",
    "\r\n",
    "df = data[['empenho_historico', 'analise']]\r\n",
    "del data\r\n",
    "df.empenho_historico = df.empenho_historico.apply(text_preprocessing)\r\n",
    "\r\n",
    "\r\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\r\n",
    "\r\n",
    "df_train, df_test = train_test_split(\r\n",
    "    df,\r\n",
    "    test_size=0.3,\r\n",
    "    random_state=RANDOM_SEED,\r\n",
    "    stratify=df.analise\r\n",
    ")\r\n",
    "\r\n",
    "\r\n",
    "lb = LabelEncoder()\r\n",
    "df_train['target'] = lb.fit_transform(df_train.analise)\r\n",
    "df_test['target'] = lb.transform(df_test.analise)\r\n",
    "\r\n",
    "np.save('classes.npy', lb.classes_)\r\n",
    "\r\n",
    "\r\n",
    "train_data_loader = create_data_loader(\r\n",
    "    df_train, tokenizer, MAX_LEN, BATCH_SIZE)\r\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\r\n",
    "\r\n",
    "print(f'Data preparation time: {(time.time() - data_prep_time):.2f}s')\r\n",
    "print()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "----------\n",
      "Train loss 0.44821290609737235 accuracy 0.8885017421602788 macro 0.3316347771061265 micro 0.8885017421602788\n",
      "Val   loss 0.42362919449806213 accuracy 0.9068825910931174 macro 0.31705590941259726 micro 0.9068825910931174\n",
      "\n",
      "Epoch time: 6.366033379236857\n",
      "Epoch 2\n",
      "----------\n",
      "Train loss 0.4398456342104409 accuracy 0.8954703832752613 macro 0.31495098039215685 micro 0.8954703832752613\n",
      "Val   loss 0.39869250636547804 accuracy 0.9068825910931174 macro 0.31705590941259726 micro 0.9068825910931174\n",
      "\n",
      "Epoch time: 4.987823597590128\n",
      "Epoch 3\n",
      "----------\n",
      "Train loss 0.4411741379234526 accuracy 0.8954703832752613 macro 0.31495098039215685 micro 0.8954703832752613\n",
      "Val   loss 0.3790783039294183 accuracy 0.9068825910931174 macro 0.31705590941259726 micro 0.9068825910931174\n",
      "\n",
      "Epoch time: 4.935704004764557\n",
      "Epoch 4\n",
      "----------\n",
      "Train loss 0.4314179074847036 accuracy 0.8954703832752613 macro 0.31495098039215685 micro 0.8954703832752613\n",
      "Val   loss 0.3795787524431944 accuracy 0.9068825910931174 macro 0.31705590941259726 micro 0.9068825910931174\n",
      "\n",
      "Epoch time: 4.897566449642182\n",
      "Epoch 5\n",
      "----------\n",
      "Train loss 0.41793192115922767 accuracy 0.8954703832752613 macro 0.31495098039215685 micro 0.8954703832752613\n",
      "Val   loss 0.3783509721979499 accuracy 0.9068825910931174 macro 0.31705590941259726 micro 0.9068825910931174\n",
      "\n",
      "Epoch time: 4.632006069024404\n",
      "Epoch 6\n",
      "----------\n",
      "Train loss 0.4166051236291726 accuracy 0.8954703832752613 macro 0.31495098039215685 micro 0.8954703832752613\n",
      "Val   loss 0.37859582202509046 accuracy 0.9068825910931174 macro 0.31705590941259726 micro 0.9068825910931174\n",
      "\n",
      "Epoch time: 4.738754061857859\n",
      "Epoch 7\n",
      "----------\n",
      "Train loss 0.4149699792679813 accuracy 0.8954703832752613 macro 0.31495098039215685 micro 0.8954703832752613\n",
      "Val   loss 0.38013555109500885 accuracy 0.9068825910931174 macro 0.31705590941259726 micro 0.9068825910931174\n",
      "\n",
      "Epoch time: 4.7794668952624\n",
      "Epoch 8\n",
      "----------\n",
      "Train loss 0.40995497732526726 accuracy 0.8954703832752613 macro 0.31495098039215685 micro 0.8954703832752613\n",
      "Val   loss 0.3799931248649955 accuracy 0.9068825910931174 macro 0.31705590941259726 micro 0.9068825910931174\n",
      "\n",
      "Epoch time: 4.727086675167084\n",
      "Epoch 9\n",
      "----------\n",
      "Train loss 0.4214341839154561 accuracy 0.8954703832752613 macro 0.31495098039215685 micro 0.8954703832752613\n",
      "Val   loss 0.38020745012909174 accuracy 0.9068825910931174 macro 0.31705590941259726 micro 0.9068825910931174\n",
      "\n",
      "Epoch time: 4.7654964327812195\n",
      "Epoch 10\n",
      "----------\n",
      "Train loss 0.4092219002130959 accuracy 0.8954703832752613 macro 0.31495098039215685 micro 0.8954703832752613\n",
      "Val   loss 0.38027176819741726 accuracy 0.9068825910931174 macro 0.31705590941259726 micro 0.9068825910931174\n",
      "\n",
      "Epoch time: 4.797392952442169\n",
      "\n",
      "BERT training time: 2979.72s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bert_time = time.time()\r\n",
    "print('Training BERT...')\r\n",
    "\r\n",
    "model = CorretudeClassifier(len(lb.classes_))\r\n",
    "model = model.to(device)\r\n",
    "\r\n",
    "# model.load_state_dict(torch.load('best_model_state.bin', map_location=torch.device(device)))\r\n",
    "\r\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, correct_bias=False)\r\n",
    "total_steps = len(train_data_loader) * EPOCHS\r\n",
    "scheduler = get_linear_schedule_with_warmup(\r\n",
    "    optimizer,\r\n",
    "    num_warmup_steps=0,\r\n",
    "    num_training_steps=total_steps\r\n",
    ")\r\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\r\n",
    "\r\n",
    "# %%\r\n",
    "history = defaultdict(list)\r\n",
    "best_accuracy = 0\r\n",
    "ant_val_loss = 0\r\n",
    "patience = 0\r\n",
    "for epoch in range(EPOCHS):\r\n",
    "    starting = time.time()\r\n",
    "    print(f'Epoch {epoch + 1}')\r\n",
    "    print('-' * 10)\r\n",
    "    train_acc, train_loss, train_macro, train_micro = train_epoch(\r\n",
    "        model,\r\n",
    "        train_data_loader,\r\n",
    "        loss_fn,\r\n",
    "        optimizer,\r\n",
    "        device,\r\n",
    "        scheduler,\r\n",
    "        len(df_train)\r\n",
    "    )\r\n",
    "    print(\r\n",
    "        f'Train loss {train_loss} accuracy {train_acc} macro {train_macro} micro {train_micro}')\r\n",
    "    val_acc, val_loss, val_macro, val_micro = eval_model(\r\n",
    "        model,\r\n",
    "        test_data_loader,\r\n",
    "        loss_fn,\r\n",
    "        device,\r\n",
    "        len(df_test)\r\n",
    "    )\r\n",
    "    print(\r\n",
    "        f'Val   loss {val_loss} accuracy {val_acc} macro {val_macro} micro {val_micro}')\r\n",
    "    print()\r\n",
    "    history['train_acc'].append(train_acc)\r\n",
    "    history['train_loss'].append(train_loss)\r\n",
    "    history['train_macro'].append(train_macro)\r\n",
    "    history['train_micro'].append(train_micro)\r\n",
    "    history['val_acc'].append(val_acc)\r\n",
    "    history['val_loss'].append(val_loss)\r\n",
    "    history['val_macro'].append(val_macro)\r\n",
    "    history['val_micro'].append(val_micro)\r\n",
    "    if val_acc > best_accuracy:\r\n",
    "        torch.save(model.state_dict(), 'best_corretudeModel_state.bin')\r\n",
    "        best_accuracy = val_acc\r\n",
    "\r\n",
    "   \r\n",
    "    print(f'Epoch time: {(time.time()-starting)/60}')\r\n",
    "\r\n",
    "print()\r\n",
    "print(f'BERT training time: {(time.time() - bert_time):.2f}s')\r\n",
    "print()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\r\n",
    "plt.plot(history['train_acc'], label='train accuracy')\r\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\r\n",
    "plt.title('Training history')\r\n",
    "plt.ylabel('Accuracy')\r\n",
    "plt.xlabel('Epoch')\r\n",
    "plt.legend()\r\n",
    "plt.ylim([0, 1])\r\n",
    "plt.savefig('Acc.png')\r\n",
    "\r\n",
    "plt.cla()\r\n",
    "plt.plot(history['train_loss'], label='train loss')\r\n",
    "plt.plot(history['val_loss'], label='validation loss')\r\n",
    "plt.title('Training history')\r\n",
    "plt.ylabel('Loss')\r\n",
    "plt.xlabel('Epoch')\r\n",
    "plt.legend()\r\n",
    "plt.ylim([0, 1])\r\n",
    "plt.savefig('Loss.png')\r\n",
    "\r\n",
    "plt.cla()\r\n",
    "plt.plot(history['train_macro'], label='train macro')\r\n",
    "plt.plot(history['val_macro'], label='validation macro')\r\n",
    "plt.title('Training history')\r\n",
    "plt.ylabel('Macro')\r\n",
    "plt.xlabel('Epoch')\r\n",
    "plt.legend()\r\n",
    "plt.ylim([0, 1])\r\n",
    "plt.savefig('Macro.png')\r\n",
    "\r\n",
    "plt.cla()\r\n",
    "plt.plot(history['train_micro'], label='train micro')\r\n",
    "plt.plot(history['val_micro'], label='validation micro')\r\n",
    "plt.title('Training history')\r\n",
    "plt.ylabel('Micro')\r\n",
    "plt.xlabel('Epoch')\r\n",
    "plt.legend()\r\n",
    "plt.ylim([0, 1])\r\n",
    "plt.savefig('Micro.png')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.00      0.00      0.00        14\n",
      "           2       0.91      1.00      0.95       224\n",
      "\n",
      "    accuracy                           0.91       247\n",
      "   macro avg       0.30      0.33      0.32       247\n",
      "weighted avg       0.82      0.91      0.86       247\n",
      "\n",
      "BERT predict time: 37.75s\n",
      "\n",
      "Finishing evaluation at 25/06/2021 15:37:08\n"
     ]
    }
   ],
   "source": [
    "def get_predictions(model, data_loader):\r\n",
    "    model = model.eval()\r\n",
    "    review_texts = []\r\n",
    "    predictions = []\r\n",
    "    prediction_probs = []\r\n",
    "    real_values = []\r\n",
    "    with torch.no_grad():\r\n",
    "        for d in data_loader:\r\n",
    "            texts = d[\"empenho_historico\"]\r\n",
    "            input_ids = d[\"input_ids\"].to(device)\r\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\r\n",
    "            targets = d[\"targets\"].to(device)\r\n",
    "            outputs = model(\r\n",
    "                input_ids=input_ids,\r\n",
    "                attention_mask=attention_mask\r\n",
    "            )\r\n",
    "            _, preds = torch.max(outputs, dim=1)\r\n",
    "            review_texts.extend(texts)\r\n",
    "            predictions.extend(preds)\r\n",
    "            prediction_probs.extend(outputs)\r\n",
    "            real_values.extend(targets)\r\n",
    "    predictions = torch.stack(predictions).cpu()\r\n",
    "    prediction_probs = torch.stack(prediction_probs).cpu()\r\n",
    "    real_values = torch.stack(real_values).cpu()\r\n",
    "    return review_texts, predictions, prediction_probs, real_values\r\n",
    "\r\n",
    "\r\n",
    "bert_time = time.time()\r\n",
    "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\r\n",
    "    model,\r\n",
    "    test_data_loader\r\n",
    ")\r\n",
    "\r\n",
    "print('Test Classification Report')\r\n",
    "print(classification_report(y_test, y_pred))\r\n",
    "\r\n",
    "print(f'BERT predict time: {(time.time() - bert_time):.2f}s')\r\n",
    "print()\r\n",
    "\r\n",
    "finish_date = datetime.now()\r\n",
    "print(f'Finishing evaluation at {finish_date.strftime(\"%d/%m/%Y %H:%M:%S\")}')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['INCONCLUSIVO', 'INCORRETO', 'OK'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.inverse_transform([0, 1, 2])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c7a8ac241a69d1dd09b5cff47f1294106fb3388ad1760be5670884b76b4d6a3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('tce': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}