{"cells":[{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["import numpy as np\r\n","import pandas as pd\r\n","import torch\r\n","from sklearn.preprocessing import LabelEncoder\r\n","from sklearn.utils import resample\r\n","from torch import nn\r\n","from torch.utils.data import DataLoader, Dataset\r\n","from transformers import BertModel, BertTokenizer\r\n","from cleantext import clean\r\n","\r\n","from preprocessing.dataprep import data_preparation, filter_tce_data\r\n","from preprocessing.text import fixColumnName\r\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["data = pd.read_csv('../database/dadosTCE.csv',\r\n","                   low_memory=False, encoding='utf-8')\r\n","data.columns = list(map(fixColumnName, data.columns))\r\n","\r\n","\r\n","data, _  = filter_tce_data(data, '../database/norel.xlsx')\r\n","# data = data.sample(100)\r\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":"(100, 45)"},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["data.shape"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\jefma\\Miniconda3\\envs\\tce\\lib\\site-packages\\pandas\\core\\generic.py:5494: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self[name] = value\n","<ipython-input-4-a6a908b36ec7>:120: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df['encodedNatureza'] = np.random.randint(1, 650, df.natureza.shape[0])\n","Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["RANDOM_SEED = 15\r\n","PRE_TRAINED_MODEL_NAME = 'neuralmind/bert-base-portuguese-cased'\r\n","MAX_LEN = 156\r\n","BATCH_SIZE = 16\r\n","EPOCHS = 10\r\n","\r\n","np.random.seed(RANDOM_SEED)\r\n","torch.manual_seed(RANDOM_SEED)\r\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n","\r\n","def clean_text(input_text):\r\n","    text = clean(\r\n","            input_text,\r\n","            fix_unicode=True,\r\n","            to_ascii=True,\r\n","            lower=True,\r\n","            normalize_whitespace=True,\r\n","            no_line_breaks=True,\r\n","            strip_lines=True,\r\n","            keep_two_line_breaks=False,\r\n","            no_urls=True,\r\n","            no_emails=True,\r\n","            no_phone_numbers=True,\r\n","            no_numbers=True,\r\n","            no_digits=True,\r\n","            no_currency_symbols=True,\r\n","            no_punct=True,\r\n","            no_emoji=True,\r\n","            replace_with_url=\"url\",\r\n","            replace_with_email=\"email\",\r\n","            replace_with_phone_number=\"telefone\",\r\n","            replace_with_number=\"\",\r\n","            replace_with_digit=\"\",\r\n","            replace_with_currency_symbol=\"BRL\",\r\n","            replace_with_punct=\" \",\r\n","            lang=\"pt\",\r\n","        )\r\n","    return text\r\n","\r\n","class TCEDataset(Dataset):\r\n","    def __init__(self, empenho, targets, tokenizer, max_len):\r\n","        self.empenho = empenho\r\n","        self.targets = targets\r\n","        self.tokenizer = tokenizer\r\n","        self.max_len = max_len\r\n","\r\n","    def __len__(self):\r\n","        return len(self.empenho)\r\n","\r\n","    def __getitem__(self, item):\r\n","        empenho = str(self.empenho[item])\r\n","        target = self.targets[item]\r\n","        encoding = self.tokenizer.encode_plus(\r\n","            empenho,\r\n","            add_special_tokens=True,\r\n","            max_length=self.max_len,\r\n","            return_token_type_ids=False,\r\n","            padding='max_length',\r\n","            return_attention_mask=True,\r\n","            return_tensors='pt',\r\n","            truncation=True\r\n","        )\r\n","        return {\r\n","            'empenho_text': empenho,\r\n","            'input_ids': encoding['input_ids'].flatten(),\r\n","            'attention_mask': encoding['attention_mask'].flatten(),\r\n","            'targets': torch.tensor(target, dtype=torch.long)\r\n","        }\r\n","\r\n","\r\n","def create_data_loader(df, tokenizer, max_len, batch_size):\r\n","    ds = TCEDataset(\r\n","        empenho=df.empenho.to_numpy(),\r\n","        targets=df.encodedNatureza.to_numpy(),\r\n","        tokenizer=tokenizer,\r\n","        max_len=max_len\r\n","    )\r\n","    return DataLoader(\r\n","        ds,\r\n","        batch_size=batch_size,\r\n","    )\r\n","\r\n","\r\n","class NaturezaClassifier(nn.Module):\r\n","    def __init__(self, n_classes):\r\n","        super(NaturezaClassifier, self).__init__()\r\n","        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\r\n","        self.drop = nn.Dropout(p=0.3)\r\n","        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\r\n","\r\n","    def forward(self, input_ids, attention_mask):\r\n","        bert_output = self.bert(\r\n","            input_ids=input_ids,\r\n","            attention_mask=attention_mask\r\n","        )\r\n","\r\n","        output = self.drop(bert_output['pooler_output'])\r\n","        return self.out(output)\r\n","\r\n","    def get_pooler(self, input_ids, attention_mask):\r\n","        bert_output = self.bert(\r\n","            input_ids=input_ids,\r\n","            attention_mask=attention_mask\r\n","        )\r\n","\r\n","        output = bert_output['pooler_output']\r\n","        return output\r\n","\r\n","\r\n","\r\n","\r\n","df = data[['empenho_historico', 'natureza_despesa_cod']]\r\n","\r\n","df.columns = ['empenho', 'natureza']\r\n","\r\n","df.empenho = df.empenho.apply(clean_text)\r\n","\r\n","lb = LabelEncoder()\r\n","lb.classes_ = np.load('../database/labelEncoder.npy', allow_pickle=True)  \r\n","df['encodedNatureza'] = np.random.randint(1, 650, df.natureza.shape[0])\r\n","\r\n","\r\n","tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\r\n","\r\n","thauan_data_loader = create_data_loader(\r\n","    df=df,  # Seu dataframe\r\n","    tokenizer=tokenizer,  \r\n","    max_len=MAX_LEN,  \r\n","    batch_size=BATCH_SIZE)\r\n","\r\n","\r\n","model = NaturezaClassifier(len(lb.classes_))  \r\n","model = model.to(device)\r\n","\r\n","model.load_state_dict(  \r\n","    torch.load(\r\n","        '../database/bert.bin',\r\n","        map_location=torch.device(device)\r\n","    )\r\n",")\r\n","\r\n","outs = []\r\n","for d in thauan_data_loader:\r\n","    text = d['empenho_text']\r\n","    input_ids = d['input_ids'].to(device)\r\n","    attention_mask = d['attention_mask'].to(device)\r\n","\r\n","    pooler = model.get_pooler(input_ids, attention_mask)\r\n","    outs.extend(pooler)\r\n","\r\n","bert_data = pd.DataFrame(\r\n","    np.array([tensor.detach().numpy() for tensor in outs]),\r\n","    columns=[f'BERT_{n}' for n in range(0, np.array([tensor.detach().numpy() for tensor in outs]).shape[1])])\r\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m<ipython-input-5-18262bcbef61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbert_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m X_train, y_train, X_test, y_test = data_preparation(\n\u001b[0m\u001b[0;32m     66\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\jefma\\OneDrive\\Documentos\\GitHub\\TCE-Internship\\src\\preprocessing\\dataprep.py\u001b[0m in \u001b[0;36mdata_preparation\u001b[1;34m(data, target, sample, test_size, categorical_columns, numerical_columns, text_columns, tfidf)\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[0mnumerical_columns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'empenhos_por_processo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m     X_train, X_test, y_train, y_test = train_test_split(\n\u001b[0m\u001b[0;32m    334\u001b[0m         data, target, test_size=test_size, random_state=15, stratify=target)\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Miniconda3\\envs\\tce\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2195\u001b[0m                      random_state=random_state)\n\u001b[0;32m   2196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2197\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2199\u001b[0m     return list(chain.from_iterable((_safe_indexing(a, train),\n","\u001b[1;32m~\\Miniconda3\\envs\\tce\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1385\u001b[0m         \"\"\"\n\u001b[0;32m   1386\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1387\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1388\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Miniconda3\\envs\\tce\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1713\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1714\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1715\u001b[1;33m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[0;32m   1716\u001b[0m                              \u001b[1;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1717\u001b[0m                              \u001b[1;34m\" number of groups for any class cannot\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."]}],"source":["categorical_columns = [\r\n","    # 'exercicio_do_orcamento_ano',\r\n","    # 'empenho_sequencial_empenho',\r\n","    'orgao',\r\n","    'orgao_sucessor_atual',\r\n","    'tipo_administracao_nome',\r\n","    'tipo_poder_nome',\r\n","    # 'classificacao_orcamentaria_descricao',\r\n","    'funcao',\r\n","    'subfuncao',\r\n","    'programa',\r\n","    'acao',\r\n","    # 'grupo_despesa',\r\n","    # 'elemento_despesa',\r\n","    # 'natureza_despesa_cod',\r\n","    # 'natureza_despesa_nome',\r\n","    'formalidade_nome',\r\n","    'modalidade_licitacao_nome',\r\n","    # 'fonte_recurso_cod',\r\n","    'fonte_recurso_nome',\r\n","    'beneficiario_cnpj',\r\n","    'beneficiario_cpf',\r\n","    'beneficiario_cpf/cnpj',\r\n","    # 'periodo',\r\n","    'empenho_numero_do_processo',\r\n","    # 'empenho_sequencial_empenho.1',\r\n","]\r\n","\r\n","text_columns = [\r\n","    # 'beneficiario_nome',\r\n","    # 'empenho_historico',\r\n","]\r\n","\r\n","numerical_columns = [\r\n","    'valor_empenhado',\r\n","    'valor_anulacao_empenho',\r\n","    # 'valor_estorno_anulacao_empenho',\r\n","    'valor_cancelamento_empenho',\r\n","    # 'valor_anulacao_cancelamento_empenho',\r\n","    'valor_saldo_do_empenho',\r\n","    'valor_liquidacao_empenho',\r\n","    'valor_anulacao_liquidacao_empenho',\r\n","    'valor_saldo_liquidado',\r\n","    'valor_ordem_de_pagamento',\r\n","    'valor_guia_recolhimento',\r\n","    'valor_anulacao_ordem_de_pagamento',\r\n","    'valor_estorno_anulacao_o._pagamento',\r\n","    'valor_estorno_guia_recolhimento',\r\n","    'valor_saldo_pago',\r\n","    'valor_saldo_a_pagar',\r\n","    'valor_a_liquidar',\r\n","    'valor_a_pagar_liquidado'\r\n","]\r\n","\r\n","\r\n","target = data.natureza_despesa_cod\r\n","\r\n","data = data.loc[:, (*categorical_columns,\r\n","                    *text_columns,\r\n","                    *numerical_columns,)]\r\n","\r\n","\r\n","data = data.reset_index(drop=True).join(bert_data)\r\n","\r\n","X_train, y_train, X_test, y_test = data_preparation(\r\n","    data,\r\n","    target,\r\n","    test_size=0.3,\r\n","    categorical_columns=categorical_columns,\r\n","    numerical_columns=numerical_columns,\r\n","    text_columns=text_columns)\r\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.svm import SVC\r\n","\r\n","clf = SVC(C=10, kernel='linear', random_state=15)\r\n","\r\n","clf.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clf.predict(X_test) == y_test.values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = clf.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report\r\n","\r\n","print(classification_report(y_test, clf.predict(X_test)))"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.4 64-bit ('tce': conda)","name":"python394jvsc74a57bd0aec94d356a37360f5d9e055019e4c65ba8db0c4673b8182eeb6101cfd9f8f53a"},"language_info":{"name":"python","version":""},"orig_nbformat":3},"nbformat":4,"nbformat_minor":2}