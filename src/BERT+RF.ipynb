{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import time\r\n","import warnings\r\n","from datetime import datetime\r\n","\r\n","import numpy as np\r\n","import pandas as pd\r\n","import torch\r\n","import string\r\n","from cleantext import clean\r\n","from sklearn.metrics import classification_report\r\n","from sklearn.model_selection import train_test_split\r\n","from sklearn.preprocessing import LabelEncoder\r\n","from sklearn.svm import SVC\r\n","from sklearn.ensemble import RandomForestClassifier\r\n","from sklearn.utils import resample\r\n","from torch import nn\r\n","from torch.utils.data import DataLoader, Dataset\r\n","from transformers import BertModel, BertTokenizer\r\n","\r\n","from preprocessing.dataprep import (data_preparation, encode_train_test,\r\n","                                    filter_tce_data)\r\n","from preprocessing.text import fixColumnName\r\n","\r\n","# warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["start_time = time.time()\r\n","start_date = datetime.now()\r\n","print(f'Starting evaluation at {start_date.strftime(\"%d/%m/%Y %H:%M:%S\")}')\r\n","print()\r\n","print('Loading data...')\r\n","\r\n","data_loading_time = time.time()\r\n","data = pd.read_csv('../database/dadosTCE.csv',\r\n","                   low_memory=False, encoding='utf-8')\r\n","print(f'Data loading time: {(time.time() - data_loading_time):.2f}s')\r\n","print()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_prep_time = time.time()\r\n","print('Preprocessing data...')\r\n","\r\n","data.columns = list(map(fixColumnName, data.columns))\r\n","data, _ = filter_tce_data(data, '../database/norel.xlsx')\r\n","# data = data.sample(100)\r\n","\r\n","RANDOM_SEED = 15\r\n","PRE_TRAINED_MODEL_NAME = 'neuralmind/bert-base-portuguese-cased'\r\n","MAX_LEN = 156\r\n","BATCH_SIZE = 16\r\n","EPOCHS = 10\r\n","\r\n","np.random.seed(RANDOM_SEED)\r\n","torch.manual_seed(RANDOM_SEED)\r\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n","\r\n","\r\n","def remove_punctuation(input_text):\r\n","    # Make translation table\r\n","    punct = string.punctuation\r\n","    # Every punctuation symbol will be replaced by a space\r\n","    trantab = str.maketrans(punct, len(punct)*' ')\r\n","    return input_text.translate(trantab)\r\n","\r\n","def clean_text(input_text):\r\n","    text = clean(\r\n","        input_text,\r\n","        fix_unicode=True,\r\n","        to_ascii=True,\r\n","        lower=True,\r\n","        normalize_whitespace=True,\r\n","        no_line_breaks=True,\r\n","        strip_lines=True,\r\n","        keep_two_line_breaks=False,\r\n","        no_urls=True,\r\n","        no_emails=True,\r\n","        no_phone_numbers=True,\r\n","        no_numbers=True,\r\n","        no_digits=True,\r\n","        no_currency_symbols=True,\r\n","        no_punct=True,\r\n","        no_emoji=True,\r\n","        replace_with_url=\"url\",\r\n","        replace_with_email=\"email\",\r\n","        replace_with_phone_number=\"telefone\",\r\n","        replace_with_number=\"\",\r\n","        replace_with_digit=\"\",\r\n","        replace_with_currency_symbol=\"\",\r\n","        replace_with_punct=\"\",\r\n","        lang=\"pt\",\r\n","    )\r\n","    return text\r\n","\r\n","\r\n","class TCEDataset(Dataset):\r\n","    def __init__(self, empenho, targets, tokenizer, max_len):\r\n","        self.empenho = empenho\r\n","        self.targets = targets\r\n","        self.tokenizer = tokenizer\r\n","        self.max_len = max_len\r\n","\r\n","    def __len__(self):\r\n","        return len(self.empenho)\r\n","\r\n","    def __getitem__(self, item):\r\n","        empenho = str(self.empenho[item])\r\n","        target = self.targets[item]\r\n","        encoding = self.tokenizer.encode_plus(\r\n","            empenho,\r\n","            add_special_tokens=True,\r\n","            max_length=self.max_len,\r\n","            return_token_type_ids=False,\r\n","            padding='max_length',\r\n","            return_attention_mask=True,\r\n","            return_tensors='pt',\r\n","            truncation=True\r\n","        )\r\n","        return {\r\n","            'empenho_text': empenho,\r\n","            'input_ids': encoding['input_ids'].flatten(),\r\n","            'attention_mask': encoding['attention_mask'].flatten(),\r\n","            'targets': torch.tensor(target, dtype=torch.long)\r\n","        }\r\n","\r\n","\r\n","def create_data_loader(df, tokenizer, max_len, batch_size):\r\n","    ds = TCEDataset(\r\n","        empenho=df.empenho.to_numpy(),\r\n","        targets=df.encodedNatureza.to_numpy(),\r\n","        tokenizer=tokenizer,\r\n","        max_len=max_len\r\n","    )\r\n","    return DataLoader(\r\n","        ds,\r\n","        batch_size=batch_size,\r\n","    )\r\n","\r\n","\r\n","class NaturezaClassifier(nn.Module):\r\n","    def __init__(self, n_classes):\r\n","        super(NaturezaClassifier, self).__init__()\r\n","        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\r\n","        self.drop = nn.Dropout(p=0.3)\r\n","        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\r\n","\r\n","    def forward(self, input_ids, attention_mask):\r\n","        bert_output = self.bert(\r\n","            input_ids=input_ids,\r\n","            attention_mask=attention_mask\r\n","        )\r\n","\r\n","        output = self.drop(bert_output['pooler_output'])\r\n","        return self.out(output), bert_output['pooler_output']\r\n","\r\n","    def get_pooler(self, input_ids, attention_mask):\r\n","        bert_output = self.bert(\r\n","            input_ids=input_ids,\r\n","            attention_mask=attention_mask\r\n","        )\r\n","\r\n","        output = bert_output['pooler_output']\r\n","        return output\r\n","\r\n","\r\n","df = data[['empenho_historico', 'natureza_despesa_cod']]\r\n","\r\n","df.columns = ['empenho', 'natureza']\r\n","\r\n","def compose_cleantext(text):\r\n","    return clean_text(remove_punctuation(text))\r\n","\r\n","df.empenho.update(df.empenho.map(compose_cleantext))\r\n","\r\n","lb = LabelEncoder()\r\n","lb.classes_ = np.load('../database/labelEncoder.npy', allow_pickle=True)\r\n","df['encodedNatureza'] = np.random.randint(1, 650, df.natureza.shape[0])\r\n","\r\n","\r\n","tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\r\n","\r\n","thauan_data_loader = create_data_loader(\r\n","    df=df,  # Seu dataframe\r\n","    tokenizer=tokenizer,\r\n","    max_len=MAX_LEN,\r\n","    batch_size=BATCH_SIZE)\r\n","\r\n","\r\n","model = NaturezaClassifier(len(lb.classes_))\r\n","model = model.to(device)\r\n","\r\n","model.load_state_dict(\r\n","    torch.load(\r\n","        '../database/bert.bin',\r\n","        map_location=torch.device(device)\r\n","    )\r\n",")\r\n","model = model.eval()\r\n","with torch.no_grad():\r\n","    outs = []\r\n","    for d in thauan_data_loader:\r\n","        text = d['empenho_text']\r\n","        input_ids = d['input_ids'].to(device)\r\n","        attention_mask = d['attention_mask'].to(device)\r\n","        _, pooler = model(input_ids, attention_mask)\r\n","        outs.extend(pooler)\r\n","\r\n","bert_data = pd.DataFrame(\r\n","    np.array([tensor.detach().numpy() for tensor in outs]),\r\n","    columns=[f'BERT_{n}' for n in range(0, np.array([tensor.detach().numpy() for tensor in outs]).shape[1])])\r\n","\r\n","categorical_columns = [\r\n","    # 'exercicio_do_orcamento_ano',\r\n","    # 'empenho_sequencial_empenho',\r\n","    'orgao',\r\n","    'orgao_sucessor_atual',\r\n","    'tipo_administracao_nome',\r\n","    'tipo_poder_nome',\r\n","    # 'classificacao_orcamentaria_descricao',\r\n","    'funcao',\r\n","    'subfuncao',\r\n","    'programa',\r\n","    'acao',\r\n","    # 'grupo_despesa',\r\n","    # 'elemento_despesa',\r\n","    # 'natureza_despesa_cod',\r\n","    # 'natureza_despesa_nome',\r\n","    'formalidade_nome',\r\n","    'modalidade_licitacao_nome',\r\n","    # 'fonte_recurso_cod',\r\n","    'fonte_recurso_nome',\r\n","    'beneficiario_cnpj',\r\n","    'beneficiario_cpf',\r\n","    'beneficiario_cpf/cnpj',\r\n","    'periodo',\r\n","    'empenho_numero_do_processo',\r\n","    # 'empenho_sequencial_empenho.1',\r\n","]\r\n","\r\n","text_columns = [\r\n","    # 'beneficiario_nome',\r\n","    # 'empenho_historico',\r\n","]\r\n","\r\n","numerical_columns = [\r\n","    'valor_empenhado',\r\n","    'valor_anulacao_empenho',\r\n","    # 'valor_estorno_anulacao_empenho',\r\n","    'valor_cancelamento_empenho',\r\n","    # 'valor_anulacao_cancelamento_empenho',\r\n","    'valor_saldo_do_empenho',\r\n","    'valor_liquidacao_empenho',\r\n","    'valor_anulacao_liquidacao_empenho',\r\n","    'valor_saldo_liquidado',\r\n","    'valor_ordem_de_pagamento',\r\n","    'valor_guia_recolhimento',\r\n","    'valor_anulacao_ordem_de_pagamento',\r\n","    'valor_estorno_anulacao_o._pagamento',\r\n","    'valor_estorno_guia_recolhimento',\r\n","    'valor_saldo_pago',\r\n","    'valor_saldo_a_pagar',\r\n","    'valor_a_liquidar',\r\n","    'valor_a_pagar_liquidado'\r\n","]\r\n","\r\n","\r\n","target = data.natureza_despesa_cod\r\n","\r\n","data = data.loc[:, (*categorical_columns,\r\n","                    *text_columns,\r\n","                    *numerical_columns,)]\r\n","\r\n","\r\n","data = data.reset_index(drop=True).join(bert_data)\r\n","\r\n","data, categorical_columns, numerical_columns = data_preparation(\r\n","    data,\r\n","    target,\r\n","    test_size=0.3,\r\n","    categorical_columns=categorical_columns,\r\n","    numerical_columns=numerical_columns,\r\n","    text_columns=text_columns,)\r\n","\r\n","X_train, X_test, y_train, y_test = train_test_split(\r\n","    data, target, test_size=0.3, random_state=15)\r\n","\r\n","X_train, X_test = encode_train_test(\r\n","    X_train, X_test, numerical_columns, categorical_columns, text_columns, tfidf=False,)\r\n","\r\n","print(f'Data preparation time: {(time.time() - data_prep_time):.2f}s')\r\n","print(f'Training shape: {X_train.shape}')\r\n","print(f'Test shape: {X_test.shape}')\r\n","print()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rf_time = time.time()\r\n","print('Training RF...')\r\n","\r\n","clf = RandomForestClassifier(n_estimators=1000, random_state=15, n_jobs=20)\r\n","clf.fit(X_train, y_train)\r\n","\r\n","print(f'RF training time: {(time.time() - rf_time):.2f}s')\r\n","print()\r\n","\r\n","rf_time = time.time()\r\n","\r\n","y_pred = clf.predict(X_test)\r\n","\r\n","print(f'RF predict time: {(time.time() - rf_time):.2f}s')\r\n","print()\r\n","\r\n","print(classification_report(y_test, clf.predict(X_test)))\r\n","print()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["finish_date = datetime.now()\r\n","print(f'Finishing evaluation at {finish_date.strftime(\"%d/%m/%Y %H:%M:%S\")}')"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.4 64-bit ('tce': conda)","name":"python394jvsc74a57bd0aec94d356a37360f5d9e055019e4c65ba8db0c4673b8182eeb6101cfd9f8f53a"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"},"orig_nbformat":3},"nbformat":4,"nbformat_minor":2}